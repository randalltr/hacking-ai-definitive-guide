# Hacking AI: The Definitive Guide

**Prompt Injection, Jailbreaking, and Offensive Techniques for Large Language Models**

This guide is a comprehensive technical manual for understanding and exploiting the vulnerabilities of modern large language models (LLMs). It is intended for security professionals, researchers, red teamers, and adversarial ML practitioners who require a clear, structured, and reproducible approach to prompt-based attacks and system behavior analysis.

No hype. No marketing. Just the techniques.

---

## Scope

This guide covers:

- Prompt injection and prompt-based adversarial control
- Jailbreaking LLMs using identity manipulation, obfuscation, and recursion
- Extraction of hidden system instructions and memory state
- Attacks on multi-turn, context-aware, and agent-based systems
- Obfuscation and filter evasion strategies
- Red team workflows, fuzzing tools, and payload libraries
- Ethics, documentation, and responsible disclosure

It includes practical examples, offensive reasoning, and reproducible tactics based on current model behavior and publicly known vulnerabilities.

---

## Who This Is For

- LLM red teamers
- Security researchers
- Offensive AI engineers
- Prompt injection analysts
- Developers testing LLM-based systems under adversarial conditions

---

## Format

The book is structured into four parts:

1. **Foundations** — LLM architecture, prompt execution, and threat models
2. **Core Exploits** — Practical injection and manipulation techniques
3. **Advanced Techniques** — Recursive, contextual, and tool-assisted attacks
4. **Red Team Operations** — Payload development, fuzzing, and disclosure

Additional appendices include labs, tools, a glossary, and a research timeline.

---

## License

This work is licensed under **Creative Commons Attribution-NonCommercial 4.0 (CC BY-NC 4.0)**.  
You may share and adapt this material with attribution, but commercial use is prohibited without permission.

---

## Status

This guide is in active development. Chapters will be written and published in order, with a focus on accuracy, depth, and reproducibility. Contributions and peer review are welcome.
